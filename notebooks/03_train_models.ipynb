{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-26T01:40:28.949837Z",
     "start_time": "2025-05-26T01:40:07.293904Z"
    }
   },
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 03_TRAIN_MODELS.IPYNB\n",
    "# Entrenamiento y Evaluación de Modelos ML para Agricultura Vertical\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENTRENAMIENTO DE MODELOS - AGRICULTURA VERTICAL\")\n",
    "print(\"=\"*60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENTRENAMIENTO DE MODELOS - AGRICULTURA VERTICAL\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. CARGA DE DATOS FEATURES ENGINEERED",
   "id": "f6278cd435cbd5ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:43:49.175755Z",
     "start_time": "2025-05-26T01:43:48.862981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# 1. CARGA DE DATOS FEATURES ENGINEERED\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1. CARGANDO DATOS CON FEATURES ENGINEERED...\")\n",
    "\n",
    "# Cargar datos con features finales\n",
    "train_data = pd.read_csv('../data/processed/train_featured.csv')\n",
    "val_data = pd.read_csv('../data/processed/validation_featured.csv')\n",
    "test_data = pd.read_csv('../data/processed/test_featured.csv')\n",
    "\n",
    "# Cargar metadata\n",
    "with open('../data/processed/feature_engineering_metadata.json', 'r') as f:\n",
    "    feature_metadata = json.load(f)\n",
    "\n",
    "selected_features = feature_metadata['selected_features']\n",
    "\n",
    "print(f\"Train shape: {train_data.shape}\")\n",
    "print(f\"Validation shape: {val_data.shape}\")\n",
    "print(f\"Test shape: {test_data.shape}\")\n",
    "print(f\"Features seleccionadas: {len(selected_features)}\")\n",
    "\n",
    "# Separar features y targets\n",
    "X_train = train_data[selected_features]\n",
    "X_val = val_data[selected_features]\n",
    "X_test = test_data[selected_features]\n",
    "\n",
    "y_train_eficiencia = train_data['eficiencia_fotosintetica_pct']\n",
    "y_val_eficiencia = val_data['eficiencia_fotosintetica_pct']\n",
    "y_test_eficiencia = test_data['eficiencia_fotosintetica_pct']\n",
    "\n",
    "# Para fotoluminiscencia (incluye eficiencia como feature)\n",
    "X_train_foto = train_data[selected_features + ['eficiencia_fotosintetica_pct']]\n",
    "X_val_foto = val_data[selected_features + ['eficiencia_fotosintetica_pct']]\n",
    "X_test_foto = test_data[selected_features + ['eficiencia_fotosintetica_pct']]\n",
    "\n",
    "y_train_foto = train_data['fotoluminiscencia_intensidad']\n",
    "y_val_foto = val_data['fotoluminiscencia_intensidad']\n",
    "y_test_foto = test_data['fotoluminiscencia_intensidad']\n",
    "\n",
    "print(f\"\\nDatos separados correctamente:\")\n",
    "print(f\"X_train eficiencia: {X_train.shape}\")\n",
    "print(f\"X_train fotoluminiscencia: {X_train_foto.shape}\")\n"
   ],
   "id": "16d0367db038e97c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. CARGANDO DATOS CON FEATURES ENGINEERED...\n",
      "Train shape: (30000, 35)\n",
      "Validation shape: (10000, 35)\n",
      "Test shape: (10000, 35)\n",
      "Features seleccionadas: 33\n",
      "\n",
      "Datos separados correctamente:\n",
      "X_train eficiencia: (30000, 33)\n",
      "X_train fotoluminiscencia: (30000, 34)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. CONFIGURACIÓN DE MODELOS",
   "id": "b80e14ff3b676209"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T01:46:29.488816Z",
     "start_time": "2025-05-26T01:46:29.472260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# 2. CONFIGURACIÓN DE MODELOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2. CONFIGURANDO MODELOS...\")\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.results = {}\n",
    "        self.training_time = {}\n",
    "\n",
    "    def get_models_config(self):\n",
    "        \"\"\"Configuración de modelos a entrenar\"\"\"\n",
    "        models_config = {\n",
    "            # Modelos lineales\n",
    "            'LinearRegression': {\n",
    "                'model': LinearRegression(),\n",
    "                'scale': False,\n",
    "                'params': {}\n",
    "            },\n",
    "            'Ridge': {\n",
    "                'model': Ridge(),\n",
    "                'scale': True,\n",
    "                'params': {\n",
    "                    'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "                }\n",
    "            },\n",
    "            'Lasso': {\n",
    "                'model': Lasso(),\n",
    "                'scale': True,\n",
    "                'params': {\n",
    "                    'alpha': [0.01, 0.1, 1.0, 10.0]\n",
    "                }\n",
    "            },\n",
    "            'ElasticNet': {\n",
    "                'model': ElasticNet(),\n",
    "                'scale': True,\n",
    "                'params': {\n",
    "                    'alpha': [0.01, 0.1, 1.0],\n",
    "                    'l1_ratio': [0.1, 0.5, 0.9]\n",
    "                }\n",
    "            },\n",
    "\n",
    "            # Modelos basados en árboles\n",
    "            'RandomForest': {\n",
    "                'model': RandomForestRegressor(random_state=42),\n",
    "                'scale': False,\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'max_depth': [10, 20, None],\n",
    "                    'min_samples_split': [2, 5],\n",
    "                    'min_samples_leaf': [1, 2]\n",
    "                }\n",
    "            },\n",
    "            'GradientBoosting': {\n",
    "                'model': GradientBoostingRegressor(random_state=42),\n",
    "                'scale': False,\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'learning_rate': [0.05, 0.1, 0.2],\n",
    "                    'max_depth': [3, 5, 7]\n",
    "                }\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'model': xgb.XGBRegressor(random_state=42),\n",
    "                'scale': False,\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'learning_rate': [0.05, 0.1, 0.2],\n",
    "                    'max_depth': [3, 5, 7],\n",
    "                    'subsample': [0.8, 1.0]\n",
    "                }\n",
    "            },\n",
    "            'LightGBM': {\n",
    "                'model': lgb.LGBMRegressor(random_state=42, verbose=-1),\n",
    "                'scale': False,\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'learning_rate': [0.05, 0.1, 0.2],\n",
    "                    'max_depth': [3, 5, 7],\n",
    "                    'num_leaves': [31, 50]\n",
    "                }\n",
    "            },\n",
    "\n",
    "            # Otros modelos\n",
    "            'SVR': {\n",
    "                'model': SVR(),\n",
    "                'scale': True,\n",
    "                'params': {\n",
    "                    'C': [0.1, 1, 10, 100],\n",
    "                    'gamma': ['scale', 'auto'],\n",
    "                    'kernel': ['rbf', 'linear']\n",
    "                }\n",
    "            },\n",
    "            'MLPRegressor': {\n",
    "                'model': MLPRegressor(random_state=42, max_iter=500),\n",
    "                'scale': True,\n",
    "                'params': {\n",
    "                    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "                    'alpha': [0.001, 0.01, 0.1],\n",
    "                    'learning_rate_init': [0.001, 0.01]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return models_config\n",
    "\n",
    "    def prepare_data(self, X_train, X_val, X_test, scale=False, scaler_name='scaler'):\n",
    "        \"\"\"Preparar datos con escalado si es necesario\"\"\"\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_val_scaled = scaler.transform(X_val)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            self.scalers[scaler_name] = scaler\n",
    "\n",
    "            return X_train_scaled, X_val_scaled, X_test_scaled\n",
    "        else:\n",
    "            return X_train.values, X_val.values, X_test.values\n",
    "\n",
    "    def evaluate_model(self, y_true, y_pred, model_name, dataset_name):\n",
    "        \"\"\"Evaluar modelo con múltiples métricas\"\"\"\n",
    "        metrics = {\n",
    "            'MAE': mean_absolute_error(y_true, y_pred),\n",
    "            'MSE': mean_squared_error(y_true, y_pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'R2': r2_score(y_true, y_pred),\n",
    "            'MAPE': mean_absolute_percentage_error(y_true, y_pred)\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def hyperparameter_tuning(self, model, params, X_train, y_train, cv=3):\n",
    "        \"\"\"Optimización de hiperparámetros\"\"\"\n",
    "        if len(params) > 0:\n",
    "            grid_search = GridSearchCV(\n",
    "                model,\n",
    "                params,\n",
    "                cv=cv,\n",
    "                scoring='neg_mean_absolute_error',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            return grid_search.best_estimator_, grid_search.best_params_\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            return model, {}\n",
    "\n",
    "    def train_models(self, X_train, X_val, X_test, y_train, y_val, y_test,\n",
    "                    target_name, quick_mode=False):\n",
    "        \"\"\"Entrenar todos los modelos para un target específico\"\"\"\n",
    "\n",
    "        models_config = self.get_models_config()\n",
    "        results = {}\n",
    "\n",
    "        print(f\"\\nEntrenando modelos para: {target_name}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        for model_name, config in models_config.items():\n",
    "            print(f\"\\nEntrenando {model_name}...\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            try:\n",
    "                # Preparar datos\n",
    "                scaler_name = f\"{target_name}_{model_name}\"\n",
    "                X_train_prep, X_val_prep, X_test_prep = self.prepare_data(\n",
    "                    X_train, X_val, X_test,\n",
    "                    scale=config['scale'],\n",
    "                    scaler_name=scaler_name\n",
    "                )\n",
    "\n",
    "                # Optimización de hiperparámetros (reducida en modo rápido)\n",
    "                if quick_mode:\n",
    "                    # Usar solo algunos parámetros en modo rápido\n",
    "                    limited_params = {}\n",
    "                    for key, values in config['params'].items():\n",
    "                        if len(values) > 2:\n",
    "                            limited_params[key] = values[:2]\n",
    "                        else:\n",
    "                            limited_params[key] = values\n",
    "                    params_to_use = limited_params\n",
    "                else:\n",
    "                    params_to_use = config['params']\n",
    "\n",
    "                best_model, best_params = self.hyperparameter_tuning(\n",
    "                    config['model'], params_to_use, X_train_prep, y_train\n",
    "                )\n",
    "\n",
    "                # Predicciones\n",
    "                y_train_pred = best_model.predict(X_train_prep)\n",
    "                y_val_pred = best_model.predict(X_val_prep)\n",
    "                y_test_pred = best_model.predict(X_test_prep)\n",
    "\n",
    "                # Evaluación\n",
    "                train_metrics = self.evaluate_model(y_train, y_train_pred, model_name, 'train')\n",
    "                val_metrics = self.evaluate_model(y_val, y_val_pred, model_name, 'val')\n",
    "                test_metrics = self.evaluate_model(y_test, y_test_pred, model_name, 'test')\n",
    "\n",
    "                # Tiempo de entrenamiento\n",
    "                training_time = time.time() - start_time\n",
    "\n",
    "                # Guardar resultados\n",
    "                results[model_name] = {\n",
    "                    'model': best_model,\n",
    "                    'best_params': best_params,\n",
    "                    'train_metrics': train_metrics,\n",
    "                    'val_metrics': val_metrics,\n",
    "                    'test_metrics': test_metrics,\n",
    "                    'training_time': training_time,\n",
    "                    'predictions': {\n",
    "                        'train': y_train_pred,\n",
    "                        'val': y_val_pred,\n",
    "                        'test': y_test_pred\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                print(f\"  - Train MAE: {train_metrics['MAE']:.3f}, R2: {train_metrics['R2']:.3f}\")\n",
    "                print(f\"  - Val MAE: {val_metrics['MAE']:.3f}, R2: {val_metrics['R2']:.3f}\")\n",
    "                print(f\"  - Test MAE: {test_metrics['MAE']:.3f}, R2: {test_metrics['R2']:.3f}\")\n",
    "                print(f\"  - Tiempo: {training_time:.1f}s\")\n",
    "                print(f\"  - Mejores params: {best_params}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  - ERROR: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        self.results[target_name] = results\n",
    "        return results\n",
    "\n",
    "# Inicializar trainer\n",
    "trainer = ModelTrainer()\n"
   ],
   "id": "49f1943fa98446cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. CONFIGURANDO MODELOS...\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. ENTRENAMIENTO PARA EFICIENCIA FOTOSINTÉTICA",
   "id": "49085cc8a3b862ea"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-26T01:48:50.137265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# 3. ENTRENAMIENTO PARA EFICIENCIA FOTOSINTÉTICA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3. ENTRENAMIENTO PARA EFICIENCIA FOTOSINTETICA...\")\n",
    "\n",
    "# Entrenar modelos (usar quick_mode=True para pruebas rápidas)\n",
    "eficiencia_results = trainer.train_models(\n",
    "    X_train, X_val, X_test,\n",
    "    y_train_eficiencia, y_val_eficiencia, y_test_eficiencia,\n",
    "    target_name='eficiencia',\n",
    "    quick_mode=False  # Cambiar a True para entrenamiento rápido\n",
    ")"
   ],
   "id": "7d54fbf5f13d53db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ENTRENAMIENTO PARA EFICIENCIA FOTOSINTETICA...\n",
      "\n",
      "Entrenando modelos para: eficiencia\n",
      "----------------------------------------\n",
      "\n",
      "Entrenando LinearRegression...\n",
      "  - Train MAE: 0.000, R2: 1.000\n",
      "  - Val MAE: 0.000, R2: 1.000\n",
      "  - Test MAE: 0.000, R2: 1.000\n",
      "  - Tiempo: 0.1s\n",
      "  - Mejores params: {}\n",
      "\n",
      "Entrenando Ridge...\n",
      "  - Train MAE: 0.000, R2: 1.000\n",
      "  - Val MAE: 0.000, R2: 1.000\n",
      "  - Test MAE: 0.000, R2: 1.000\n",
      "  - Tiempo: 3.6s\n",
      "  - Mejores params: {'alpha': 0.1}\n",
      "\n",
      "Entrenando Lasso...\n",
      "  - Train MAE: 0.008, R2: 1.000\n",
      "  - Val MAE: 0.008, R2: 1.000\n",
      "  - Test MAE: 0.008, R2: 1.000\n",
      "  - Tiempo: 1.1s\n",
      "  - Mejores params: {'alpha': 0.01}\n",
      "\n",
      "Entrenando ElasticNet...\n",
      "  - Train MAE: 0.018, R2: 1.000\n",
      "  - Val MAE: 0.018, R2: 1.000\n",
      "  - Test MAE: 0.018, R2: 1.000\n",
      "  - Tiempo: 1.4s\n",
      "  - Mejores params: {'alpha': 0.01, 'l1_ratio': 0.9}\n",
      "\n",
      "Entrenando RandomForest...\n",
      "  - Train MAE: 0.001, R2: 1.000\n",
      "  - Val MAE: 0.001, R2: 1.000\n",
      "  - Test MAE: 0.001, R2: 1.000\n",
      "  - Tiempo: 1864.3s\n",
      "  - Mejores params: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Entrenando GradientBoosting...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. ENTRENAMIENTO PARA FOTOLUMINISCENCIA",
   "id": "f2685d2f800ceb4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n4. ENTRENAMIENTO PARA FOTOLUMINISCENCIA...\")\n",
    "\n",
    "# Entrenar modelos para fotoluminiscencia\n",
    "fotolum_results = trainer.train_models(\n",
    "    X_train_foto, X_val_foto, X_test_foto,\n",
    "    y_train_foto, y_val_foto, y_test_foto,\n",
    "    target_name='fotoluminiscencia',\n",
    "    quick_mode=False\n",
    ")"
   ],
   "id": "12ea99dfcc982fae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. COMPARACIÓN DE MODELOS",
   "id": "cb3aa45b74b128b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# 5. COMPARACIÓN DE MODELOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5. COMPARACION DE MODELOS...\")\n",
    "\n",
    "def create_comparison_table(results_dict):\n",
    "    \"\"\"Crear tabla comparativa de resultados\"\"\"\n",
    "    comparison_data = []\n",
    "\n",
    "    for target_name, target_results in results_dict.items():\n",
    "        for model_name, model_results in target_results.items():\n",
    "            row = {\n",
    "                'Target': target_name,\n",
    "                'Model': model_name,\n",
    "                'Train_MAE': model_results['train_metrics']['MAE'],\n",
    "                'Val_MAE': model_results['val_metrics']['MAE'],\n",
    "                'Test_MAE': model_results['test_metrics']['MAE'],\n",
    "                'Train_R2': model_results['train_metrics']['R2'],\n",
    "                'Val_R2': model_results['val_metrics']['R2'],\n",
    "                'Test_R2': model_results['test_metrics']['R2'],\n",
    "                'Training_Time': model_results['training_time']\n",
    "            }\n",
    "            comparison_data.append(row)\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    return comparison_df\n",
    "\n",
    "# Crear tabla comparativa\n",
    "all_results = trainer.results\n",
    "comparison_df = create_comparison_table(all_results)\n",
    "\n",
    "# Mostrar mejores modelos por target\n",
    "print(\"\\nRESULTADOS COMPARATIVOS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for target in ['eficiencia', 'fotoluminiscencia']:\n",
    "    target_df = comparison_df[comparison_df['Target'] == target].copy()\n",
    "    target_df = target_df.sort_values('Test_MAE')\n",
    "\n",
    "    print(f\"\\n{target.upper()}:\")\n",
    "    print(target_df[['Model', 'Test_MAE', 'Test_R2', 'Training_Time']].head(5).to_string(index=False))\n",
    "\n",
    "    # Mejor modelo\n",
    "    best_model = target_df.iloc[0]\n",
    "    print(f\"\\nMEJOR MODELO: {best_model['Model']}\")\n",
    "    print(f\"  - Test MAE: {best_model['Test_MAE']:.3f}\")\n",
    "    print(f\"  - Test R2: {best_model['Test_R2']:.3f}\")\n",
    "    print(f\"  - Tiempo entrenamiento: {best_model['Training_Time']:.1f}s\")"
   ],
   "id": "3c5372fae35ae2fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " 6. ANÁLISIS DE RESIDUOS",
   "id": "4300e95dbcaceffb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# 6. ANÁLISIS DE RESIDUOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n6. ANALISIS DE RESIDUOS...\")\n",
    "\n",
    "def plot_residuals_analysis(y_true, y_pred, model_name, target_name):\n",
    "    \"\"\"Análisis de residuos para un modelo\"\"\"\n",
    "    residuals = y_true - y_pred\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Análisis de Residuos - {model_name} ({target_name})')\n",
    "\n",
    "    # 1. Residuos vs Predicciones\n",
    "    axes[0,0].scatter(y_pred, residuals, alpha=0.6)\n",
    "    axes[0,0].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0,0].set_xlabel('Predicciones')\n",
    "    axes[0,0].set_ylabel('Residuos')\n",
    "    axes[0,0].set_title('Residuos vs Predicciones')\n",
    "\n",
    "    # 2. Q-Q Plot\n",
    "    from scipy import stats\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[0,1])\n",
    "    axes[0,1].set_title('Q-Q Plot')\n",
    "\n",
    "    # 3. Histograma de residuos\n",
    "    axes[1,0].hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[1,0].set_xlabel('Residuos')\n",
    "    axes[1,0].set_ylabel('Frecuencia')\n",
    "    axes[1,0].set_title('Distribución de Residuos')\n",
    "\n",
    "    # 4. Predicciones vs Valores reales\n",
    "    axes[1,1].scatter(y_true, y_pred, alpha=0.6)\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    axes[1,1].plot([min_val, max_val], [min_val, max_val], 'red', linestyle='--')\n",
    "    axes[1,1].set_xlabel('Valores Reales')\n",
    "    axes[1,1].set_ylabel('Predicciones')\n",
    "    axes[1,1].set_title('Predicciones vs Valores Reales')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Estadísticas de residuos\n",
    "    print(f\"\\nEstadísticas de residuos para {model_name}:\")\n",
    "    print(f\"  - Media: {residuals.mean():.3f}\")\n",
    "    print(f\"  - Std: {residuals.std():.3f}\")\n",
    "    print(f\"  - Skewness: {stats.skew(residuals):.3f}\")\n",
    "    print(f\"  - Kurtosis: {stats.kurtosis(residuals):.3f}\")\n",
    "\n",
    "# Análisis para mejores modelos\n",
    "for target in ['eficiencia', 'fotoluminiscencia']:\n",
    "    target_df = comparison_df[comparison_df['Target'] == target].copy()\n",
    "    best_model_name = target_df.sort_values('Test_MAE').iloc[0]['Model']\n",
    "\n",
    "    # Obtener predicciones del mejor modelo\n",
    "    best_results = all_results[target][best_model_name]\n",
    "\n",
    "    if target == 'eficiencia':\n",
    "        y_true = y_test_eficiencia\n",
    "    else:\n",
    "        y_true = y_test_foto\n",
    "\n",
    "    y_pred = best_results['predictions']['test']\n",
    "\n",
    "    plot_residuals_analysis(y_true, y_pred, best_model_name, target)"
   ],
   "id": "129c1bca4e9b3766"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7. ANÁLISIS DE IMPORTANCIA DE FEATURES",
   "id": "9ef1842ca6631d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# 7. ANÁLISIS DE IMPORTANCIA DE FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n7. ANALISIS DE IMPORTANCIA DE FEATURES...\")\n",
    "\n",
    "def plot_feature_importance(results, target_name, top_k=15):\n",
    "    \"\"\"Graficar importancia de features para modelos basados en árboles\"\"\"\n",
    "\n",
    "    tree_models = ['RandomForest', 'GradientBoosting', 'XGBoost', 'LightGBM']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, model_name in enumerate(tree_models):\n",
    "        if model_name in results and i < 4:\n",
    "            model = results[model_name]['model']\n",
    "\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                if target_name == 'eficiencia':\n",
    "                    feature_names = selected_features\n",
    "                else:\n",
    "                    feature_names = selected_features + ['eficiencia_fotosintetica_pct']\n",
    "\n",
    "                # Crear DataFrame de importancia\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': model.feature_importances_\n",
    "                }).sort_values('importance', ascending=False).head(top_k)\n",
    "\n",
    "                # Graficar\n",
    "                axes[i].barh(range(len(importance_df)), importance_df['importance'])\n",
    "                axes[i].set_yticks(range(len(importance_df)))\n",
    "                axes[i].set_yticklabels(importance_df['feature'])\n",
    "                axes[i].set_xlabel('Importancia')\n",
    "                axes[i].set_title(f'{model_name} - {target_name}')\n",
    "                axes[i].invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Graficar importancia para ambos targets\n",
    "for target in ['eficiencia', 'fotoluminiscencia']:\n",
    "    if target in all_results:\n",
    "        plot_feature_importance(all_results[target], target)"
   ],
   "id": "54170ff19501a7dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7bfa15bee9be3f88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
